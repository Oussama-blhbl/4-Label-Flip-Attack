{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb278fbf-006b-49c2-a1c6-e188af85f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, classification_report, precision_recall_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import shap\n",
    "import numpy as np\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor, FeatureCollisionAttack\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from art.utils import to_categorical\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d215da3-8c53-44ae-b718-bade63767a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "data = pd.read_csv('Preprocessed_Data.csv')\n",
    "\n",
    "# Rename columns to remove special characters\n",
    "data.rename(columns={\n",
    "    'Air temperature [K]': 'Air_temperature_K',\n",
    "    'Process temperature [K]': 'Process_temperature_K',\n",
    "    'Rotational speed [rpm]': 'Rotational_speed_rpm',\n",
    "    'Torque [Nm]': 'Torque_Nm',\n",
    "    'Tool wear [min]': 'Tool_wear_min'\n",
    "}, inplace=True)\n",
    "\n",
    "# Create the 'No failure' column\n",
    "data['No failure'] = 1 - data['Machine failure']\n",
    "\n",
    "# Define features and target\n",
    "X = data[['Type', 'Air_temperature_K', 'Process_temperature_K', 'Rotational_speed_rpm', 'Torque_Nm', 'Tool_wear_min']]\n",
    "y = data[['No failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']].idxmax(axis=1)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "set(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840e7908-f420-49b7-b619-314bb686fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HDF', 'No failure', 'OSF', 'PWF', 'TWF'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize stratified split\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y_encoded):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "\n",
    "# Apply SMOTE to oversample the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define all possible target names\n",
    "all_classes = label_encoder.classes_\n",
    "set(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36b121c7-5faa-40b2-8285-132c8b11a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models with the best parameters\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        max_depth=35, \n",
    "        min_samples_split=3, \n",
    "        n_estimators=150, \n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        learning_rate=0.4, \n",
    "        max_depth=5, \n",
    "        n_estimators=400, \n",
    "        subsample=1.0, \n",
    "        random_state=42\n",
    "    ),\n",
    "    'Neural Network': MLPClassifier(\n",
    "        activation='relu', \n",
    "        hidden_layer_sizes=(50, 50), \n",
    "        solver='adam', \n",
    "        max_iter=350, \n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65797714-73cd-4b86-838e-c023cfdc5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the poisoning function for multiclass classification\n",
    "def label_flip_poisoning(X_train, y_train, poison_percentage, target_class):\n",
    "    # Target Class 1: Flipping \"no failure\" (y_train == 1) to the 6th failure (RNF, y_train == 6)\n",
    "    if target_class == 1:\n",
    "        # Find indices where y_train indicates no failure (y_train == 1)\n",
    "        no_failure_indices = np.where(y_train == 1)[0]\n",
    "        \n",
    "        # Determine the number of labels to flip based on the poison percentage\n",
    "        num_to_flip = int(poison_percentage * len(no_failure_indices))\n",
    "        \n",
    "        # Randomly select indices to flip\n",
    "        flip_indices = np.random.choice(no_failure_indices, size=num_to_flip, replace=False)\n",
    "        \n",
    "        # Create poisoned labels by copying y_train\n",
    "        y_train_poisoned = y_train.copy()\n",
    "        \n",
    "        # Flip the selected \"no failure\" labels (1) to the 6th failure (RNF, y_train == 6)\n",
    "        y_train_poisoned[flip_indices] = 0\n",
    "    \n",
    "    # Target Class 2: Flipping failure types (2 to 6) to \"no failure\" (y_train == 1)\n",
    "    else:\n",
    "        # Find indices where y_train indicates failure (y_train in [2, 3, 4, 5, 6])\n",
    "        failure_indices = np.where(y_train > 1)[0]\n",
    "        \n",
    "        # Determine the number of labels to flip based on the poison percentage\n",
    "        num_to_flip = int(poison_percentage * len(failure_indices))\n",
    "        \n",
    "        # Randomly select indices to flip\n",
    "        flip_indices = np.random.choice(failure_indices, size=num_to_flip, replace=False)\n",
    "        \n",
    "        # Create poisoned labels by copying y_train\n",
    "        y_train_poisoned = y_train.copy()\n",
    "        \n",
    "        # Flip the selected failure labels (2 to 6) to \"no failure\" (1)\n",
    "        y_train_poisoned[flip_indices] = 1\n",
    "    \n",
    "    return X_train, y_train_poisoned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee283cf-5d1f-4947-a9fd-7be820e27dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect suspicious labels using KNN and return the most common neighbors for correction\n",
    "def identify_suspicious_labels(X_train, y_train, threshold=0.7, n_neighbors=3):\n",
    "    # Ensure X_train is a NumPy array for KNN compatibility\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        X_train = X_train.values\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_train)\n",
    "    \n",
    "    # Identify mismatches between the predicted labels and the actual labels\n",
    "    mismatches = (y_train != y_pred_knn)\n",
    "    suspicious_idx = np.where(mismatches)[0]\n",
    "    \n",
    "    # Initialize a list to store the most common neighbor class for each suspicious point\n",
    "    most_common_neighbors = []\n",
    "    \n",
    "    # Loop through suspicious indices and find the most common neighbor class\n",
    "    for idx in suspicious_idx:\n",
    "        neighbor_indices = knn.kneighbors([X_train[idx]], return_distance=False)[0]\n",
    "        \n",
    "        # Find the most common class among the neighbors\n",
    "        neighbor_classes = y_train[neighbor_indices]  # Since y_train is a NumPy array, we use direct indexing\n",
    "        most_common_class = np.bincount(neighbor_classes).argmax()  # Get the most frequent class\n",
    "        most_common_neighbors.append(most_common_class)\n",
    "    \n",
    "    print(f\"Number of suspicious indices: {len(suspicious_idx)}\")\n",
    "    return suspicious_idx, most_common_neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e286198a-c365-4c2b-9a4d-eba62c9b0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the suspicious labels by assigning them the most common class among neighbors\n",
    "def correct_labels_failure_type(X_train, y_train, suspicious_idx, most_common_neighbors):\n",
    "    corrected_labels = y_train.copy()\n",
    "    \n",
    "    # Replace the suspicious labels with the most common class from neighbors\n",
    "    for i, idx in enumerate(suspicious_idx):\n",
    "        corrected_labels.iloc[idx] = most_common_neighbors[i]\n",
    "    \n",
    "    return corrected_labels\n",
    "# Define label deletion\n",
    "def delete_labels(X_train, y_train, suspicious_idx):\n",
    "    X_train_cleaned = np.delete(X_train, suspicious_idx, axis=0)\n",
    "    y_train_cleaned = np.delete(y_train, suspicious_idx, axis=0)\n",
    "    return X_train_cleaned, y_train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bffa45-60f4-410d-b5e9-9880743ae891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Target Class: 2\n",
      "Intervention: No Intervention\n",
      "Poison percentage: 0\n",
      "Poison percentage: 0.1\n",
      "Poison percentage: 0.2\n",
      "Poison percentage: 0.3\n",
      "Poison percentage: 0.4\n",
      "Poison percentage: 0.5\n",
      "Intervention: Correction\n",
      "Poison percentage: 0\n",
      "Number of suspicious indices: 213\n",
      "Poison percentage: 0.1\n",
      "Number of suspicious indices: 2014\n",
      "Poison percentage: 0.2\n",
      "Number of suspicious indices: 3437\n",
      "Poison percentage: 0.3\n",
      "Number of suspicious indices: 4458\n",
      "Poison percentage: 0.4\n",
      "Number of suspicious indices: 5029\n",
      "Poison percentage: 0.5\n",
      "Number of suspicious indices: 5076\n",
      "Intervention: Deletion\n",
      "Poison percentage: 0\n",
      "Number of suspicious indices: 213\n",
      "Poison percentage: 0.1\n",
      "Number of suspicious indices: 2006\n",
      "Poison percentage: 0.2\n",
      "Number of suspicious indices: 3392\n",
      "Poison percentage: 0.3\n",
      "Number of suspicious indices: 4411\n",
      "Poison percentage: 0.4\n",
      "Number of suspicious indices: 4977\n",
      "Poison percentage: 0.5\n",
      "Number of suspicious indices: 5187\n",
      "Model: XGBoost\n",
      "Target Class: 2\n",
      "Intervention: No Intervention\n",
      "Poison percentage: 0\n"
     ]
    }
   ],
   "source": [
    "# Define the poisoning percentages to test\n",
    "poison_percentages = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "target_classes = [1, 2]  # 0 for no failure, 1 for failure\n",
    "# Initialize dictionary to store FDR results\n",
    "fdr_results = {'Model': [], 'Target': [], 'Intervention': [], '0%': [], '10%': [], '20%': [], '30%': [], '40%': [], '50%': [], 'Mean': []}\n",
    "\n",
    "# Define the interventions\n",
    "interventions = ['No Intervention', 'Correction', 'Deletion']\n",
    "\n",
    "# Loop through each model\n",
    "for name, model in models.items():\n",
    "    print(f'Model: {name}')\n",
    "    \n",
    "    # Loop through each target class (only focusing on target class 1)\n",
    "    for target_class in [2]:  # Focus only on failure class\n",
    "        print(f'Target Class: {target_class}')\n",
    "        \n",
    "        # Loop through each intervention type (No Intervention, Correction, Deletion)\n",
    "        for intervention in interventions:\n",
    "            print(f'Intervention: {intervention}')\n",
    "            \n",
    "            # Store the model name, target class, and intervention type in the results dictionary\n",
    "            fdr_results['Model'].append(name)\n",
    "            fdr_results['Target'].append(target_class)\n",
    "            fdr_results['Intervention'].append(intervention)\n",
    "            \n",
    "            # Store a list to calculate the mean FDR values later\n",
    "            fdr_values = []\n",
    "            \n",
    "            # Loop through each poisoning percentage (including 0% for clean data)\n",
    "            for poison_percentage in poison_percentages:\n",
    "                print(f'Poison percentage: {poison_percentage}')\n",
    "\n",
    "                # Poison the training data\n",
    "                X_train_poisoned, y_train_poisoned = label_flip_poisoning(X_train_res, y_train_res, poison_percentage, target_class)\n",
    "                \n",
    "                # Apply label correction or deletion if needed\n",
    "                if intervention == 'Correction':\n",
    "                    suspicious_indices, most_common_neighbors = identify_suspicious_labels(X_train_poisoned, y_train_poisoned)\n",
    "                    y_train_poisoned[suspicious_indices] = most_common_neighbors  # Correct labels based on neighbors\n",
    "                elif intervention == 'Deletion':\n",
    "                    suspicious_indices, _ = identify_suspicious_labels(X_train_poisoned, y_train_poisoned)\n",
    "                    X_train_poisoned, y_train_poisoned = delete_labels(X_train_poisoned, y_train_poisoned, suspicious_indices)\n",
    "\n",
    "                # Train the model on the (possibly corrected or cleaned) poisoned data\n",
    "                model.fit(X_train_poisoned, y_train_poisoned)\n",
    "                \n",
    "                # Make predictions on the clean test set\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                # Calculate Failure Detection Rate (FDR) for class 1 (failure)\n",
    "                true_failure = (y_test == 2)\n",
    "                true_positive_failures = ((y_pred == 2) & (y_test == 2)).sum()\n",
    "                fdr = true_positive_failures / true_failure.sum() if true_failure.sum() > 0 else 0\n",
    "                \n",
    "                # Store the FDR based on the poison percentage for the current intervention and target class\n",
    "                fdr_results[f'{int(poison_percentage * 100)}%'].append(fdr)\n",
    "                fdr_values.append(fdr)\n",
    "\n",
    "            # Calculate the mean FDR across all poisoning percentages\n",
    "            fdr_results['Mean'].append(sum(fdr_values) / len(fdr_values))\n",
    "\n",
    "# Convert the FDR results dictionary to a DataFrame\n",
    "fdr_df = pd.DataFrame(fdr_results)\n",
    "\n",
    "# Display the FDR results\n",
    "print(\"Failure Detection Rate (FDR) Results:\")\n",
    "display(fdr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb51d09-07a7-4f1f-b126-24f9afdc9dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
